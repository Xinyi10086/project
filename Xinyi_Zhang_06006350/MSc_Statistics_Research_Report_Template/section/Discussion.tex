\section{Conclusion and Discussion}
\label{sec:disc}

This study introduces two complementary frameworks for sparse polynomial model selection in noisy settings:
The first uses Bayesian evidence when only the response is noisy and an ODR approach for the EIV setting, where noise affects both the predictors and the response.
The main findings can be summarised as follows:
\begin{itemize}
    \item The Bayesian razor method reliably identifies parsimonious models under moderate response noise, directly quantifying posterior model probabilities in accordance with Occam’s razor.
    
    The simulation experiments for the Bayesian razor method demonstrated that, in the case where noise is added only to the response variable, the method consistently identified the correct polynomial structure under low to moderate noise levels. Posterior probabilities were strongly concentrated on the true model, and coefficient estimates closely matched the ground truth. Although the noise variance increased, the Bayesian razor still maintained accurate model selection up to relatively high noise levels. Only when the noise variance became excessively large (e.g., $\sigma \ge 3.9$) did the method break down. These findings highlight the robustness of Bayesian evidence in balancing model fit and complexity in the presence of response noise.
    \item The STLSQ framework provides a simple and efficient approach for enforcing sparsity in polynomial regression, but its performance degrades under increasing response noise. But both methods failed to select the exact sparse solution.

    In the simulations, both the OLS-based and BIC-based thresholding rules produced coefficient estimates close to the ground truth. However, as the noise variance increased ($\sigma = 0.3, 0.5$), the recovered coefficients became increasingly biased. Although the BIC-based strategy generally yielded more stable fits than the OLS-based rule, neither approach was able to maintain correct sparsity. 

    \item The STLSQ-ODR framework effectively mitigates bias caused by noisy predictors, showing robust recovery of governing equations under Gaussian, Student-t, and correlated noise.
    
    In the EIV problem where both predictors and responses were contaminated with Gaussian, Student-t, and correlated noise, the proposed STLSQ-ODR framework exhibited strong recovery of the true sparse polynomial structure under small to moderate noise. Both OLS-based and BIC-based thresholding strategies worked well in the low-noise regime, but as the noise increased, the BIC-based approach consistently outperformed the OLS-based rule by eliminating spurious terms and preserving sparsity. Under heavy-tailed and correlated noise, BIC-based selection remained relatively stable, while OLS-based methods became less reliable and tended to include irrelevant coefficients. Although both approaches eventually failed when the noise level was too large, the overall results confirm that STLSQ-ODR provides a robust and noise-aware mechanism for sparse recovery in challenging settings.
    \item across noise regimes, BIC-based thresholding demonstrates stronger stability than OLS-based selection, though both methods deteriorate when noise becomes excessively large.
\end{itemize}

During the simulation studies, we identified limitations inherent in the model selection approaches used. For the Bayesian razor method, reliable performance hinges on the assumption that only response noise is present. Once predictor variables are corrupted, the likelihood structure becomes intractable, rendering direct Bayesian evidence calculations infeasible. Approximate Bayesian methods, such as variational inference or MCMC with latent predictor modelling \citep{gunapati2022}, could be explored as future work. For the STLSQ-ODR framework, the simulation results revealed sensitivity to the choice of threshold $\lambda$: while BIC-based selection proved relatively robust, it tended to oversimplify models under heavy-tailed or high-variance noise, collapsing sparse polynomials into incorrect linear approximations. Moreover, both approaches rely on synthetic datasets with controlled noise structures, which may not fully reflect the heterogeneity and dependence encountered in real experimental measurements. Finally, the one-dimensional polynomial setting considered here represents a simplified testbed; scaling these methods to multivariate and high-dimensional systems remains an open challenge, where identifiability and computational tractability may be severely strained.

Overall, the main findings appear robust under moderate noise but degrade when the signal-to-noise ratio falls below a critical threshold. In such regimes, both Bayesian evidence and ODR-based methods exhibit systematic biases—underscoring that no estimator is immune to extreme noise contamination. Nevertheless, the complementarity of the two approaches is that Bayesian razor excels in balancing fit and complexity when predictor variables are reliable, while STLSQ-ODR provides resilience when both predictors and responses are noisy. This suggests a promising future direction in combining Bayesian evidence with ODR-based sparsification into a unified framework, enabling comprehensive and principled model selection across a broad range of noisy scenarios.